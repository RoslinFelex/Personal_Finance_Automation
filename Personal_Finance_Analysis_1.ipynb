{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFAtw-M05hvm"
      },
      "outputs": [],
      "source": [
        "# =================================================================\n",
        "# --- 0) Initial Setup and Google Drive Integration ---\n",
        "# =================================================================\n",
        "# NOTES:\n",
        "# - Privacy: This runs inside Google Colab. Only YOU can access your Google Drive.\n",
        "#   Mounting here does not expose your Drive or environment to anyone else.\n",
        "# - Automation: Input file (transactions) is read directly from Drive, and final\n",
        "#   Excel with charts/summaries is saved back into the same folder. No manual steps.\n",
        "# - Input requirements: File should contain at least these columns:\n",
        "#   ['Date', 'Narration', 'Withdrawal Amt', 'Deposit Amt', 'Closing Balance']\n",
        "# =================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the base directory for input/output files\n",
        "base_drive_path = '/content/drive/MyDrive/Financial_Analysis'\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(base_drive_path, exist_ok=True)\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# --- 1) Read the Input File from Google Drive with Validation ---\n",
        "# =================================================================\n",
        "# Checks if the given file exists in your Drive folder, validates Excel/CSV formats\n",
        "# =================================================================\n",
        "\n",
        "while True:\n",
        "    input_filename = input(\"Please enter the name of your transaction file (e.g., Transaction.xls): \")\n",
        "    input_file_path = os.path.join(base_drive_path, input_filename)\n",
        "\n",
        "    if not os.path.exists(input_file_path):\n",
        "        print(\"\\n‚õîÔ∏è Error: File not found. Please check the file name and try again.\")\n",
        "    else:\n",
        "        try:\n",
        "            if input_filename.endswith(('.xls', '.xlsx')):\n",
        "                df = pd.read_excel(input_file_path)\n",
        "            else:\n",
        "                df = pd.read_csv(input_file_path)\n",
        "            print(f\"‚úÖ Successfully read input file from: {input_file_path}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚õîÔ∏è Error: Could not read the file. Details: {e}\")\n",
        "\n",
        "# =================================================================\n",
        "# --- 2) Model Loading with Quantization ---\n",
        "# =================================================================\n",
        "# NOTE:\n",
        "# - This part is OPTIONAL and COMMENTED OUT.\n",
        "# - If you want to fine-tune or run Phi-3-mini locally, uncomment and install.\n",
        "# - Not needed for core analysis (works fine without it).\n",
        "# =================================================================\n",
        "\n",
        "#!pip install --upgrade --force-reinstall transformers accelerate bitsandbytes\n",
        "\n",
        "#bnb_config = BitsAndBytesConfig(\n",
        "    #load_in_4bit=True,\n",
        "    #bnb_4bit_quant_type=\"nf4\",\n",
        "    #bnb_4bit_compute_dtype=torch.float16,\n",
        "    #bnb_4bit_use_double_quant=True,\n",
        "#)\n",
        "\n",
        "#model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#model = AutoModelForCausalLM.from_pretrained(\n",
        "    #model_name,\n",
        "    #device_map=\"auto\",\n",
        "    #quantization_config=bnb_config,\n",
        "    #torch_dtype=torch.float16,\n",
        "#)\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# --- 3) Data Pre-processing Functions ---\n",
        "# =================================================================\n",
        "# Cleaning & standardizing raw transaction data (amounts, narrations).\n",
        "# - clean_amount: removes symbols, brackets, text from withdrawal/deposit amounts.\n",
        "# - normalize_narration: trims narration text for grouping recurring merchants.\n",
        "# =================================================================\n",
        "\n",
        "def clean_amount(x):\n",
        "    if pd.isna(x): return 0.0\n",
        "    s = str(x).strip()\n",
        "    if s == \"\": return 0.0\n",
        "    s = re.sub(r'\\(|\\)', '', s)\n",
        "    s = re.sub(r\"[‚Çπ$‚Ç¨,]\", \"\", s)\n",
        "    s = re.sub(r\"\\bINR\\b|\\bRs\\b|\\bCR\\b|\\bDr\\b\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r\"[^0-9\\.\\-]\", \"\", s)\n",
        "    if s in [\"\", \"-\", \".\", \"-.\"]: return 0.0\n",
        "    try:\n",
        "        return float(s)\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def normalize_narration(s):\n",
        "    if pd.isna(s): return \"unknown\"\n",
        "    s = str(s).lower()\n",
        "    s = re.sub(r'\\d+', '', s)\n",
        "    s = re.sub(r'[^a-z\\s]', ' ', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s[:60]\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# --- 4) Perform Data Analysis and Summarization ---\n",
        "# =================================================================\n",
        "# Breakdown:\n",
        "# - 4A: Monthly & Category Analysis\n",
        "# - 4B: Compact Transaction Text\n",
        "# - 4C: Monthly Summaries + % Change\n",
        "# - 4D: Visualization (Trend Chart - Line Plot)\n",
        "# - 4E: Visualization (Stacked Bar Chart)\n",
        "# =================================================================\n",
        "\n",
        "df['Withdrawal'] = df['Withdrawal Amt'].apply(clean_amount)\n",
        "df['Deposit'] = df['Deposit Amt'].apply(clean_amount)\n",
        "\n",
        "total_withdrawals = df['Withdrawal'].sum()\n",
        "total_deposits = df['Deposit'].sum()\n",
        "\n",
        "largest_withdrawal, largest_withdrawal_row = 0.0, None\n",
        "if (df['Withdrawal'] > 0).any():\n",
        "    idx_w = df['Withdrawal'].idxmax()\n",
        "    largest_withdrawal = df.loc[idx_w, 'Withdrawal']\n",
        "    largest_withdrawal_row = df.loc[idx_w, ['Date','Narration','Withdrawal','Closing Balance']]\n",
        "\n",
        "smallest_withdrawal, smallest_withdrawal_row = 0.0, None\n",
        "if (df['Withdrawal'] > 0).any():\n",
        "    idx_s = df[df['Withdrawal'] > 0]['Withdrawal'].idxmin()\n",
        "    smallest_withdrawal = df.loc[idx_s, 'Withdrawal']\n",
        "    smallest_withdrawal_row = df.loc[idx_s, ['Date','Narration','Withdrawal','Closing Balance']]\n",
        "\n",
        "largest_deposit, largest_deposit_row = 0.0, None\n",
        "if (df['Deposit'] > 0).any():\n",
        "    idx_d = df['Deposit'].idxmax()\n",
        "    largest_deposit = df.loc[idx_d, 'Deposit']\n",
        "    largest_deposit_row = df.loc[idx_d, ['Date','Narration','Deposit','Closing Balance']]\n",
        "\n",
        "# Recurring patterns\n",
        "df['norm_narr'] = df['Narration'].apply(normalize_narration)\n",
        "recurring = (df[df['Withdrawal'] > 0]\n",
        "              .groupby('norm_narr')\n",
        "              .agg(count=('Withdrawal','size'), total_spent=('Withdrawal','sum'))\n",
        "              .sort_values(['count','total_spent'], ascending=False)\n",
        "              .reset_index()\n",
        "              .head(10))\n",
        "\n",
        "# =================================================================\n",
        "# --- 4A) Monthly & Category Analysis ---\n",
        "# Handles parsing dates, creating MonthYear, categorizing transactions\n",
        "# (if 'Category' not in file, auto-assigns based on narration keywords).\n",
        "# =================================================================\n",
        "# NOTE: It's recommended to add a 'Category' column manually in your Excel\n",
        "# for higher accuracy. The auto-categorization is just a fallback.\n",
        "# =================================================================\n",
        "\n",
        "# ----------------------------\n",
        "# Robust Date read + parsing\n",
        "# ----------------------------\n",
        "\n",
        "# Read file but keep Date as raw string to avoid early/incorrect Excel parsing\n",
        "if input_filename.endswith(('.xls', '.xlsx')):\n",
        "    # use converters so only Date column preserved as string\n",
        "    df = pd.read_excel(input_file_path, converters={'Date': str})\n",
        "else:\n",
        "    # read_csv with Date forced to string\n",
        "    df = pd.read_csv(input_file_path, dtype={'Date': str})\n",
        "\n",
        "# Keep a copy of the original date string for debugging/sanity checks\n",
        "df['_orig_Date_str'] = df['Date'].astype(str)\n",
        "\n",
        "# Robust parse function: try explicit day-first formats first, then fall back to dayfirst=True\n",
        "def robust_parse_date(s):\n",
        "    if pd.isna(s):\n",
        "        return pd.NaT\n",
        "    s = str(s).strip()\n",
        "    if s == \"\" or s.lower() in ('nan','none','nat'):\n",
        "        return pd.NaT\n",
        "\n",
        "    # List of common formats to try (day-first formats first)\n",
        "    fmts = [\n",
        "        \"%d-%m-%Y\", \"%d/%m/%Y\", \"%d.%m.%Y\",\n",
        "        \"%Y-%m-%d\", \"%Y/%m/%d\",\n",
        "        \"%m/%d/%Y\", \"%m-%d-%Y\"\n",
        "    ]\n",
        "    for fmt in fmts:\n",
        "        try:\n",
        "            return pd.to_datetime(s, format=fmt)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Final fallback: let pandas infer but with dayfirst=True\n",
        "    try:\n",
        "        return pd.to_datetime(s, dayfirst=True, errors='coerce')\n",
        "    except Exception:\n",
        "        return pd.NaT\n",
        "\n",
        "# Apply robust parsing and overwrite Date with proper Timestamps\n",
        "df['Date'] = df['_orig_Date_str'].apply(robust_parse_date)\n",
        "\n",
        "# Quick sanity print (first 10) so you can see parsed result vs original\n",
        "print(\"\\nSample original date strings vs parsed Date (first 10 rows):\")\n",
        "print(df[['_orig_Date_str','Date']].head(10).to_string(index=False))\n",
        "\n",
        "# Now create MonthYear in readable format (e.g., Jul-2025)\n",
        "df['MonthYear'] = df['Date'].dt.strftime('%b-%Y')\n",
        "\n",
        "# ----------------------------\n",
        "# Numeric columns cleaning\n",
        "# ----------------------------\n",
        "# (re-use your clean_amount function)\n",
        "df['Withdrawal'] = df['Withdrawal Amt'].apply(clean_amount)\n",
        "df['Deposit'] = df['Deposit Amt'].apply(clean_amount)\n",
        "\n",
        "# ----------------------------\n",
        "# Category handling (use existing if present)\n",
        "# ----------------------------\n",
        "if 'Category' not in df.columns:\n",
        "    def categorize_transaction(narration):\n",
        "        narration = str(narration).lower()\n",
        "        if \"loan\" in narration: return \"Loan\"\n",
        "        elif any(w in narration for w in [\"uber\",\"ola\",\"flight\",\"train\",\"bus\"]): return \"Travel\"\n",
        "        elif any(w in narration for w in [\"swiggy\",\"zomato\",\"food\",\"restaurant\"]): return \"Food\"\n",
        "        elif any(w in narration for w in [\"amazon\",\"flipkart\",\"myntra\",\"shopping\"]): return \"Shopping\"\n",
        "        elif any(w in narration for w in [\"netflix\",\"spotify\",\"prime\",\"subscription\"]): return \"Subscription\"\n",
        "        elif any(w in narration for w in [\"payment\"]): return \"Payment\"\n",
        "        elif any(w in narration for w in [\"refund\"]): return \"Refund\"\n",
        "        else: return \"Other\"\n",
        "    df['Category'] = df['Narration'].apply(categorize_transaction)\n",
        "\n",
        "# ----------------------------\n",
        "# Monthly category spend (Withdrawal sums)\n",
        "# ----------------------------\n",
        "monthly_category_sum = (\n",
        "    df[df['Withdrawal'] > 0]\n",
        "      .groupby(['MonthYear','Category'], as_index=False)\n",
        "      .agg(total_spent=('Withdrawal','sum'))\n",
        ")\n",
        "\n",
        "# Ensure MonthYear ordering is sensible ‚Äî optional: convert MonthYear back to a sortable datetime key\n",
        "# Create a helper column for true month start (for proper chronological sorting later)\n",
        "df['MonthStart'] = df['Date'].dt.to_period('M').dt.to_timestamp()\n",
        "monthly_category_sum = monthly_category_sum.merge(\n",
        "    df[['MonthYear','MonthStart']].drop_duplicates(subset=['MonthYear']),\n",
        "    on='MonthYear', how='left'\n",
        ").sort_values(['MonthStart','Category']).drop(columns=['MonthStart'])\n",
        "\n",
        "# ----------------------------\n",
        "# Maximum spent per category (correct alignment)\n",
        "# ----------------------------\n",
        "# Sort so the highest withdrawal per category comes first, then pick first() per group\n",
        "max_spent_per_category = (\n",
        "    df[df['Withdrawal'] > 0]\n",
        "      .sort_values(['Category','Withdrawal'], ascending=[True, False])\n",
        "      .groupby('Category', as_index=False)\n",
        "      .first()[['Category','Date','Narration','Withdrawal']]\n",
        ")\n",
        "\n",
        "# Format Date consistently as dd-mm-YYYY for display/export\n",
        "max_spent_per_category['Date'] = pd.to_datetime(max_spent_per_category['Date'], errors='coerce').dt.strftime('%d-%m-%Y')\n",
        "\n",
        "# ----------------------------\n",
        "# Build transactions_text with formatted date & category\n",
        "# ----------------------------\n",
        "def fmt_dt_for_text(ts):\n",
        "    if pd.isnull(ts):\n",
        "        return \"\"\n",
        "    try:\n",
        "        return pd.to_datetime(ts).strftime(\"%d/%m/%Y\")\n",
        "    except:\n",
        "        return str(ts)\n",
        "\n",
        "transactions_text = \"\\n\".join([\n",
        "    f\"{fmt_dt_for_text(row['Date'])} | [CATEGORY: {row['Category']}] | {row['Narration'][:60]} | W:{row['Withdrawal']:.2f} | D:{row['Deposit']:.2f} | Bal:{row.get('Closing Balance','')}\"\n",
        "    for _, row in df.head(50).iterrows()\n",
        "])\n",
        "\n",
        "# ----------------------------\n",
        "# Print checks\n",
        "# ----------------------------\n",
        "#print(\"\\nMonthly category spend sample:\")\n",
        "#print(monthly_category_sum.head(10).to_string(index=False))\n",
        "#print(\"\\nMaximum spent per category (sample):\")\n",
        "#print(max_spent_per_category.head(10).to_string(index=False))\n",
        "\n",
        "# ‚úÖ Fix date alignment for max spent per category\n",
        "max_spent_per_category = (\n",
        "    df[df['Withdrawal'] > 0]\n",
        "      .sort_values(['Category','Withdrawal'], ascending=[True,False])\n",
        "      .groupby('Category')\n",
        "      .first()\n",
        "      .reset_index()[['Category','Date','Narration','Withdrawal']]\n",
        ")\n",
        "\n",
        "# ‚úÖ Format Date columns consistently\n",
        "monthly_category_sum['MonthYear'] = monthly_category_sum['MonthYear']\n",
        "max_spent_per_category['Date'] = max_spent_per_category['Date'].dt.strftime('%d-%m-%Y')\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# --- 4B) Compact transaction text for LLM ---\n",
        "# Prepares a short list of transactions as plain text\n",
        "# (useful if you want to prompt an LLM with structured data).\n",
        "# =================================================================\n",
        "\n",
        "transactions_text = \"\\n\".join([\n",
        "    f\"{row['Date']} | {row['Narration'][:60]} | W:{row['Withdrawal']:.2f} | D:{row['Deposit']:.2f} | Bal:{row['Closing Balance']}\"\n",
        "    for _, row in df.head(50).iterrows()\n",
        "])\n",
        "\n",
        "numeric_summary = f\"\"\"\n",
        "NUMERIC_SUMMARY:\n",
        "Total withdrawals = {total_withdrawals:.2f}\n",
        "Total deposits = {total_deposits:.2f}\n",
        "Largest withdrawal = {largest_withdrawal:.2f} {('on '+str(largest_withdrawal_row['Date'])+' | '+str(largest_withdrawal_row['Narration']) ) if largest_withdrawal_row is not None else ''}\n",
        "Smallest withdrawal = {smallest_withdrawal:.2f} {('on '+str(smallest_withdrawal_row['Date'])+' | '+str(smallest_withdrawal_row['Narration']) ) if smallest_withdrawal_row is not None else ''}\n",
        "Largest deposit = {largest_deposit:.2f} {('on '+str(largest_deposit_row['Date'])+' | '+str(largest_deposit_row['Narration']) ) if largest_deposit_row is not None else ''}\n",
        "Top recurring merchant patterns:\n",
        "{recurring.to_string(index=False)}\n",
        "\n",
        "Monthly spend by category:\n",
        "{monthly_category_sum.to_string(index=False)}\n",
        "\n",
        "Maximum spent per category with details:\n",
        "{max_spent_per_category.to_string(index=False)}\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚úÖ Numeric + Monthly summary calculated:\\n\", numeric_summary)\n",
        "\n",
        "# =================================================================\n",
        "# --- 4C) Monthly Summaries + % Change for LLM ---\n",
        "# Prepares human-readable summaries + calculates % change month-over-month\n",
        "# =================================================================\n",
        "\n",
        "# Calculate % change month-to-month per category\n",
        "monthly_pct_change = (\n",
        "    monthly_category_sum\n",
        "    .pivot(index='MonthYear', columns='Category', values='total_spent')\n",
        "    .pct_change()\n",
        "    .fillna(0) * 100\n",
        ")\n",
        "\n",
        "# Build text summary for LLM\n",
        "monthly_summary_text = \"MONTHLY SUMMARY:\\n\"\n",
        "for month, group in monthly_category_sum.groupby('MonthYear'):\n",
        "    monthly_summary_text += f\"\\n{month}:\\n\"\n",
        "    for _, row in group.iterrows():\n",
        "        monthly_summary_text += f\"  {row['Category']}: {row['total_spent']:.2f}\\n\"\n",
        "\n",
        "monthly_summary_text += \"\\nPERCENTAGE CHANGE (MoM -Increase or Decrease in Spending to Previous Month) :\\n\"\n",
        "for month, row in monthly_pct_change.iterrows():\n",
        "    monthly_summary_text += f\"\\n{month}:\\n\"\n",
        "    for cat, val in row.dropna().items():\n",
        "        monthly_summary_text += f\"  {cat}: {val:.2f}%\\n\"\n",
        "\n",
        "print(\"\\n‚úÖ Monthly summary text prepared for LLM:\\n\")\n",
        "print(monthly_summary_text)\n",
        "\n",
        "\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =================================================================\n",
        "# --- 4D) Visualization (Trend Chart - Line Plot) ---\n",
        "# Category-wise spending over time (withdrawals) plotted as line chart\n",
        "# =================================================================\n",
        "\n",
        "print(\"Category Wise Spending Trend:\\n\")\n",
        "fig1, ax1 = plt.subplots(figsize=(10,6))\n",
        "\n",
        "for cat in monthly_category_sum['Category'].unique():\n",
        "    cat_data = monthly_category_sum[monthly_category_sum['Category']==cat]\n",
        "    ax1.plot(cat_data['MonthYear'], cat_data['total_spent'], marker='o', label=cat)\n",
        "\n",
        "ax1.set_title(\"Monthly Spending by Category (Withdrawals)\")\n",
        "ax1.set_xlabel(\"Month-Year\")\n",
        "ax1.set_ylabel(\"Total Withdrawal\")\n",
        "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
        "ax1.legend(title=\"Category\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "fig1.tight_layout()\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# --- 4E) Visualization (Stacked Bar Chart) ---\n",
        "# Category-wise spending stacked for each month (better comparative view)\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\nStacked Bar Graph of Category Wise Spending:\\n\")\n",
        "\n",
        "pivot_df = (\n",
        "    monthly_category_sum\n",
        "    .pivot(index='MonthYear', columns='Category', values='total_spent')\n",
        "    .fillna(0)\n",
        ")\n",
        "\n",
        "# Convert MonthYear to datetime for correct sorting\n",
        "pivot_df.index = pd.to_datetime(pivot_df.index, format='%b-%Y')\n",
        "pivot_df = pivot_df.sort_index()\n",
        "\n",
        "fig2, ax2 = plt.subplots(figsize=(12,8))\n",
        "pivot_df.plot(kind='bar', stacked=True, ax=ax2)\n",
        "\n",
        "ax2.set_title(\"Monthly Spending by Category (Withdrawals)\", fontsize=16)\n",
        "ax2.set_xlabel(\"Month-Year\", fontsize=12)\n",
        "ax2.set_ylabel(\"Total Withdrawal\", fontsize=12)\n",
        "plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
        "ax2.legend(title=\"Category\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "fig2.tight_layout()\n",
        "\n",
        "# =================================================================\n",
        "# --- 4F) Closing Balance Safety Analysis ---\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\nClosing Balance Safety Check:\\n\")\n",
        "\n",
        "# Ensure Date is datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "\n",
        "# Get last available closing balance for each month\n",
        "monthly_closing_balance = (\n",
        "    df.sort_values('Date')\n",
        "      .groupby(df['Date'].dt.to_period('M'))\n",
        "      .last()[['Closing Balance']]\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# Rename columns for clarity\n",
        "monthly_closing_balance.rename(columns={'Date': 'Month'}, inplace=True)\n",
        "\n",
        "# Classify safety status\n",
        "def classify_balance(balance):\n",
        "    try:\n",
        "        balance_val = float(str(balance).replace(',', ''))\n",
        "        return \"‚úÖ Safe\" if balance_val >= 0 else \"‚ö†Ô∏è In Debt\"\n",
        "    except:\n",
        "        return \"Unknown\"\n",
        "\n",
        "monthly_closing_balance['Status'] = monthly_closing_balance['Closing Balance'].apply(classify_balance)\n",
        "\n",
        "# Print summary\n",
        "print(monthly_closing_balance.to_string(index=False))\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# --- 5) LLM Prompting and Generation (Optional) ---\n",
        "# =================================================================\n",
        "# COMMENTED OUT\n",
        "# - Uses Phi-3-mini or any other SLM/LLM to generate insights.\n",
        "# - Relies on summaries prepared in 4B + 4C, so no recalculations inside the LLM.\n",
        "# =================================================================\n",
        "\n",
        "#user_prompt = input(\"\\nüí¨ Enter any additional analysis prompt for the LLM (or press Enter to skip): \")\n",
        "\n",
        "#messages = [\n",
        "#   {\"role\": \"system\", \"content\": \"You are a financial assistant. Use only the provided summaries, do not invent numbers.\"},\n",
        "#   {\"role\": \"user\", \"content\": f\"\"\"\n",
        "#Here are the financial summaries:\n",
        "\n",
        "#NUMERIC SUMMARY:\n",
        "#{numeric_summary}\n",
        "\n",
        "#{monthly_summary_text}\n",
        "\n",
        "#TRANSACTIONS (sample):\n",
        "#{transactions_text}\n",
        "\n",
        "#TASKS:\n",
        "#1. Compare withdrawals between the last two months and give % change.\n",
        "#2. Identify which category had the most withdrawal overall.\n",
        "#3. Give the maximum withdrawal for each category (with date + narration).\n",
        "#4. Based on category patterns, suggest practical ways to adjust spending.\n",
        "#5. Keep it concise, actionable, and do not recalc totals.\n",
        "\n",
        "#IMPORTANT:\n",
        "#- Only use the numbers provided above.\n",
        "#- Do not invent values or currency symbols.\n",
        "#\"\"\"}\n",
        "#]\n",
        "\n",
        "#def ask_llm(messages, max_new_tokens=400):\n",
        "#   input_ids = tokenizer.apply_chat_template(\n",
        "#       messages,\n",
        "#       add_generation_prompt=True,\n",
        "#       return_tensors=\"pt\"\n",
        "#    ).to(model.device)\n",
        "\n",
        "#    with torch.no_grad():\n",
        "#        gen_ids = model.generate(\n",
        "#            input_ids,\n",
        "#            max_new_tokens=max_new_tokens,\n",
        "#            do_sample=True,\n",
        "#            temperature=0.7,\n",
        "#            top_p=0.9\n",
        "#       )\n",
        "\n",
        "#    return tokenizer.decode(gen_ids[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "#analysis = ask_llm(messages, max_new_tokens=400)\n",
        "\n",
        "#print(\"\\n----- LLM INTERPRETATION -----\\n\")\n",
        "#print(analysis)\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# --- 6) Save Outputs + Both Charts to Excel ---\n",
        "# =================================================================\n",
        "# - Saves everything into one Excel file in Google Drive.\n",
        "# - Sheets: NumericSummary, Recurring, MonthlyCategorySum, MaxPerCategory,\n",
        "#   MonthlySummaryText, MonthlyPctChange, and embedded Charts.\n",
        "# =================================================================\n",
        "\n",
        "!pip install xlsxwriter\n",
        "\n",
        "current_time_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_filename = f\"Spending_Analysis_{current_time_str}.xlsx\"\n",
        "output_file_path = os.path.join(base_drive_path, output_filename)\n",
        "\n",
        "with pd.ExcelWriter(output_file_path, engine=\"xlsxwriter\") as writer:\n",
        "    # Numeric summary\n",
        "    pd.DataFrame([{\n",
        "        \"total_withdrawals\": total_withdrawals,\n",
        "        \"total_deposits\": total_deposits,\n",
        "        \"largest_withdrawal\": largest_withdrawal,\n",
        "        \"smallest_withdrawal\": smallest_withdrawal,\n",
        "        \"largest_deposit\": largest_deposit\n",
        "    }]).to_excel(writer, sheet_name=\"NumericSummary\", index=False)\n",
        "\n",
        "    # Recurring merchants\n",
        "    recurring.to_excel(writer, sheet_name=\"Recurring\", index=False)\n",
        "\n",
        "    # Monthly category spend\n",
        "    monthly_category_sum.to_excel(writer, sheet_name=\"MonthlyCategorySum\", index=False)\n",
        "\n",
        "    # Max spent per category\n",
        "    max_spent_per_category.to_excel(writer, sheet_name=\"MaxPerCategory\", index=False)\n",
        "\n",
        "    # LLM Insights\n",
        "    #pd.DataFrame([{\"LLM_Insights\": analysis}]).to_excel(writer, sheet_name=\"Insights\", index=False)\n",
        "\n",
        "\n",
        "    # Monthly summary text\n",
        "    pd.DataFrame([{\"Monthly_Summary_Text\": monthly_summary_text}]).to_excel(\n",
        "        writer, sheet_name=\"MonthlySummaryText\", index=False\n",
        "    )\n",
        "\n",
        "    # Percentage change MoM\n",
        "    monthly_pct_change.reset_index().to_excel(writer, sheet_name=\"MonthlyPctChange\", index=False)\n",
        "\n",
        "    # Add to Excel output\n",
        "    monthly_closing_balance.to_excel(writer, sheet_name=\"ClosingBalanceCheck\", index=False)\n",
        "\n",
        "    # --- Add charts sheet ---\n",
        "    workbook = writer.book\n",
        "    worksheet = workbook.add_worksheet(\"Charts\")\n",
        "    writer.sheets[\"Charts\"] = worksheet\n",
        "\n",
        "    # Save fig1 (line chart) into memory and embed\n",
        "    imgdata1 = io.BytesIO()\n",
        "    fig1.savefig(imgdata1, format=\"png\", bbox_inches=\"tight\")\n",
        "    imgdata1.seek(0)\n",
        "    worksheet.insert_image(\"B2\", \"trend_chart.png\", {\"image_data\": imgdata1})\n",
        "\n",
        "    # Save fig2 (stacked bar) into memory and embed below first chart\n",
        "    imgdata2 = io.BytesIO()\n",
        "    fig2.savefig(imgdata2, format=\"png\", bbox_inches=\"tight\")\n",
        "    imgdata2.seek(0)\n",
        "    worksheet.insert_image(\"B25\", \"stacked_chart.png\", {\"image_data\": imgdata2})\n",
        "\n",
        "plt.close(fig1)\n",
        "plt.close(fig2)\n",
        "\n",
        "print(f\"\\n‚úÖ Analysis saved to Google Drive as: {output_file_path}\")\n",
        "print(\"‚úÖ Both charts embedded in 'Charts' sheet\")\n"
      ]
    }
  ]
}